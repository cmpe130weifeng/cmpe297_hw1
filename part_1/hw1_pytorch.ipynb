{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download MNIST dataset\n",
    "train_data = datasets.MNIST(\n",
    "    root = \"data\",\t\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = \"data\",\n",
    "    train = False,\n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.targets.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one training example\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(train_data.data[0].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.targets[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for training with DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "# The Dataset retrieves our datasetâ€™s features and labels one sample at a time.\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(train_data, \n",
    "                        batch_size=64, \n",
    "                        shuffle=True,\n",
    "                        num_workers=1),\n",
    "    'test': DataLoader(test_data, \n",
    "                        batch_size=64, \n",
    "                        shuffle=True,\n",
    "                        num_workers=1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.fc = nn.Linear(7*7*32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.fc(x)\n",
    "        return output, x    # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Iter [100/937] Loss: 0.0566\n",
      "Epoch [1/5], Iter [200/937] Loss: 0.0768\n",
      "Epoch [1/5], Iter [300/937] Loss: 0.0483\n",
      "Epoch [1/5], Iter [400/937] Loss: 0.0145\n",
      "Epoch [1/5], Iter [500/937] Loss: 0.0489\n",
      "Epoch [1/5], Iter [600/937] Loss: 0.0238\n",
      "Epoch [1/5], Iter [700/937] Loss: 0.1135\n",
      "Epoch [1/5], Iter [800/937] Loss: 0.0762\n",
      "Epoch [1/5], Iter [900/937] Loss: 0.0824\n",
      "Epoch [2/5], Iter [100/937] Loss: 0.0196\n",
      "Epoch [2/5], Iter [200/937] Loss: 0.0190\n",
      "Epoch [2/5], Iter [300/937] Loss: 0.0286\n",
      "Epoch [2/5], Iter [400/937] Loss: 0.0208\n",
      "Epoch [2/5], Iter [500/937] Loss: 0.1178\n",
      "Epoch [2/5], Iter [600/937] Loss: 0.0041\n",
      "Epoch [2/5], Iter [700/937] Loss: 0.0187\n",
      "Epoch [2/5], Iter [800/937] Loss: 0.0619\n",
      "Epoch [2/5], Iter [900/937] Loss: 0.1200\n",
      "Epoch [3/5], Iter [100/937] Loss: 0.0167\n",
      "Epoch [3/5], Iter [200/937] Loss: 0.0239\n",
      "Epoch [3/5], Iter [300/937] Loss: 0.0734\n",
      "Epoch [3/5], Iter [400/937] Loss: 0.0568\n",
      "Epoch [3/5], Iter [500/937] Loss: 0.0018\n",
      "Epoch [3/5], Iter [600/937] Loss: 0.0012\n",
      "Epoch [3/5], Iter [700/937] Loss: 0.0132\n",
      "Epoch [3/5], Iter [800/937] Loss: 0.0704\n",
      "Epoch [3/5], Iter [900/937] Loss: 0.0824\n",
      "Epoch [4/5], Iter [100/937] Loss: 0.0407\n",
      "Epoch [4/5], Iter [200/937] Loss: 0.0032\n",
      "Epoch [4/5], Iter [300/937] Loss: 0.0096\n",
      "Epoch [4/5], Iter [400/937] Loss: 0.0057\n",
      "Epoch [4/5], Iter [500/937] Loss: 0.0797\n",
      "Epoch [4/5], Iter [600/937] Loss: 0.0090\n",
      "Epoch [4/5], Iter [700/937] Loss: 0.0611\n",
      "Epoch [4/5], Iter [800/937] Loss: 0.0078\n",
      "Epoch [4/5], Iter [900/937] Loss: 0.0319\n",
      "Epoch [5/5], Iter [100/937] Loss: 0.0028\n",
      "Epoch [5/5], Iter [200/937] Loss: 0.0198\n",
      "Epoch [5/5], Iter [300/937] Loss: 0.0063\n",
      "Epoch [5/5], Iter [400/937] Loss: 0.0098\n",
      "Epoch [5/5], Iter [500/937] Loss: 0.0082\n",
      "Epoch [5/5], Iter [600/937] Loss: 0.0014\n",
      "Epoch [5/5], Iter [700/937] Loss: 0.0304\n",
      "Epoch [5/5], Iter [800/937] Loss: 0.0344\n",
      "Epoch [5/5], Iter [900/937] Loss: 0.0069\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "from torch.autograd import Variable\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "def train(num_epochs):\n",
    "    cnn.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = cnn(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                       %(epoch+1, num_epochs, i+1, len(train_data)//64, loss.data.item()))\n",
    "\n",
    "train(num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "cnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in loaders['test']:\n",
    "    images = Variable(images)\n",
    "    outputs, _ = cnn(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb238e68b64afb71c1779c62df48529c52fce49f4a42c7f6f4dd07ab1407e2a7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
